{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agenda - Given a sequence of previous characters, model the probability distribution of the next character in the sequence. \n",
    "\n",
    "Here we try harry potter text\n",
    "\n",
    "We will be using kears for this note "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 626260\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "path = \"./../data/harry_potter_3.txt\"\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 54\n"
     ]
    }
   ],
   "source": [
    "total_chars = sorted(list(set(text)))\n",
    "print('total chars:', len(total_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dictionaries to map characters to IDs and vice-a-versa\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(total_chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(total_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints/sequences: 626220\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "maxlen = 40 # length of data window\n",
    "step = 1    # step by which to shift the data window \n",
    "\n",
    "sentences = []    # this stores X\n",
    "next_chars = []   # this stores y\n",
    "\n",
    "# (i:i+40) as X, (i+40) as corresponding y\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen]) # get sentence\n",
    "    next_chars.append(text[i + maxlen])   # get next character\n",
    "    \n",
    "\n",
    "num_of_sentences = len(sentences)\n",
    "\n",
    "print('Number of datapoints/sequences:', num_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "#Vectorize the input \n",
    "\n",
    "# X will be a 3D tensor - num_of_sentences * maxlen * total_chars\n",
    "# y will be 2D tensor - sentences * total_chars\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((num_of_sentences, maxlen, len(total_chars)), dtype=np.bool)\n",
    "y = np.zeros((num_of_sentences, len(total_chars)), dtype=np.bool)\n",
    "\n",
    "# populate the tensors\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# lstm takes a single slice of 3D tensor along num_of_sentences axiss\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(total_chars)))) \n",
    "\n",
    "# add a dense layer - takes 128 input and spits output of num_of_chars \n",
    "model.add(Dense(len(total_chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preds is scores over output space (characters)\n",
    "# Its nothing but - confidence the RNN currently assigns to each character coming next in the sequence\n",
    "\n",
    "# we convert scores into probability distribution and pick the best bet. \n",
    "\n",
    "# Temperature. We can also play with the temperature of the Softmax during sampling. Decreasing the temperature \n",
    "# from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. \n",
    "# Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, \n",
    "# etc). In particular, setting temperature very near zero will give the most likely thing\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds) # convert scores to prob via softmax\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas) # return the one with max probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "626220/626220 [==============================] - 690s - loss: 1.6568   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ered up all his presents and his birthda\"\n",
      "ered up all his presents and his birthda\n",
      "y and harry and her had to the firebolt and startly.\n",
      "\n",
      "\"what had the truth, it was the truth, harry and her had a black to the starting the class to the firebolt of the firebolt of the starting to the firebolt and the firebolt to the truth to the firebolt with a starting to harry and the stand and her had the truth and the class with his back of the starting to the truth to the class of the fireb\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ered up all his presents and his birthda\"\n",
      "ered up all his presents and his birthda\n",
      "y.\n",
      "\n",
      "\"it was it, some was the dementors made him of the firebolt to one was\n",
      "black had the momin to the started at harry and starting his firebolt about looking the other had your hand and course growisting the sitch for his unter a striughter to large snape to the firebolt... it had the firebolt and made to harry was malfoy started to be agair.\n",
      "\n",
      "\"long!\" said harry, course and the first to prof\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ered up all his presents and his birthda\"\n",
      "ered up all his presents and his birthda\n",
      "ll thing.\n",
      "\n",
      "\"around,\" stare picked his weas!\"\n",
      "\n",
      "fecled, an used to hermione was cluss ron.\n",
      "\n",
      "harry looking lightening from buncalio fighter. her had stidden\n",
      "barde urording harry. ron wrefe\n",
      "contics. please, at harryle to do\n",
      "will der yes, egntic toward like a haghter along do sirius minispered trouhs and looked to fit.\n",
      "\n",
      "whis year that in weekly, choudly.\n",
      "\n",
      "the head lap over, hagriding her t\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ered up all his presents and his birthda\"\n",
      "ered up all his presents and his birthda\n",
      "y standing nouse ifsides dreemspoate\n",
      "there wereghally room; neceregannly.\n",
      "\n",
      "\"d'velurliver!\" uscance, forking, you coun ristuy\n",
      "whitw sne muttreyels. \"as fiven to veech a be.\n",
      "anyone!\"\n",
      "though insiver one will over. harry, lupin to the last\n",
      "pitled out lirded mives.\n",
      "\n",
      "\"the octase. \"a about dranoned had mib as\n",
      "clase, finds,\" serrout twh her faind. profove laver yhand you'd tryess\n",
      "ttat's out all\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "626220/626220 [==============================] - 691s - loss: 1.4244   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\"\n",
      "sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\n",
      "ally started the stairs of the stand and they was a stand was a stairs and stand the classes and started the stand was one of the started one of the boggart than the stairs of the team in the stairs to the states and stand and started the stairs and started the started with the sign the stand and stairs and staring and at the stairs of the started of the stairs and stand and started to the state w\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\"\n",
      "sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\n",
      "ally stairing the worst to the\n",
      "stations was stand lights for the mine marents were that he\n",
      "lean, and the madam pomfrey was mand across the castle\n",
      "great the castle, whis staring back at the suttered.\n",
      "\n",
      "\"what what he woke that where we been a statily\n",
      "the shart and they except long the wizard and possessly resched\n",
      "of the shoulder in the dogs of the weas about the reasinably, and standing of wiz\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\"\n",
      "sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\n",
      "ached the stant?\"\n",
      "\n",
      "\"get sus-an as the getting the crimips to\n",
      "passed about that s.yeb?\"\n",
      "\n",
      "\"you just be a very eamons his neass boy -- why they're\n",
      "you midamempt into they sthupped to get at\n",
      "a bit, that seed harry.\"\n",
      "\n",
      "they thought mile yes,\" said ron.\n",
      "\n",
      "\"come yes in worry going to cle's not thistered back in the\n",
      "visibly.\n",
      "\n",
      "i snape's broken resicellw ssyes,\" said snape him fleengams.\n",
      "\n",
      "it w\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\"\n",
      "sleep in my bag.\"\n",
      "\n",
      "harry yawned. he re\n",
      "llusts next folclay, bioticutiw eyverboptecping\n",
      "fine lutin't.\"\n",
      "\n",
      "\"wo i' this -\n",
      "\n",
      "i dull\n",
      "just win' noted more.\"\n",
      "\n",
      "a suyser, casevergedingod ohnes in suppooled worm into his pupksen\n",
      "away, as staided near one oldes, about. he driftly longat side,\n",
      "stats\n",
      "whe, id ho've snape. scabberstiss, and he don't left down.\n",
      "\n",
      "smeal,\" he sardlege's \n",
      "firstard. it sirghly dwar... bent in doorbth were on\n",
      "co\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "  7680/626220 [..............................] - ETA: 688s - loss: 1.3914"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y,batch_size=128,epochs=1)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1) # pick an index at random\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        \n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen] # pick sentence at randomly gerenated index\n",
    "        generated += sentence\n",
    "        \n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        sys.stdout.write(\"\\n\")\n",
    "        \n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(total_chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1. # put the sentence in 1-hot format\n",
    "                \n",
    "            preds = model.predict(x, verbose=0)[0] # make the model spit out predictions\n",
    "            \n",
    "            next_index = sample(preds, diversity) # choose a character index\n",
    "            next_char = indices_char[next_index]  # get the corresponding chracater\n",
    "            \n",
    "            generated += next_char                # append this character to the sentence\n",
    "            sentence = sentence[1:] + next_char   # now shift the the sentence by one character\n",
    "            \n",
    "            sys.stdout.write(next_char)           # write the character to buffer\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
