{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agenda - Given a sequence of previous characters, model the probability distribution of the next character in the sequence. \n",
    "\n",
    "Here we try harry potter text\n",
    "\n",
    "We will be using kears for this note "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 626260\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "path = \"./../data/harry_potter_3.txt\"\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 54\n"
     ]
    }
   ],
   "source": [
    "total_chars = sorted(list(set(text)))\n",
    "print('total chars:', len(total_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dictionaries to map characters to IDs and vice-a-versa\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(total_chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(total_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints/sequences: 626220\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "maxlen = 40 # length of data window\n",
    "step = 1    # step by which to shift the data window \n",
    "\n",
    "sentences = []    # this stores X\n",
    "next_chars = []   # this stores y\n",
    "\n",
    "# (i:i+40) as X, (i+40) as corresponding y\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen]) # get sentence\n",
    "    next_chars.append(text[i + maxlen])   # get next character\n",
    "    \n",
    "\n",
    "num_of_sentences = len(sentences)\n",
    "\n",
    "print('Number of datapoints/sequences:', num_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "#Vectorize the input \n",
    "\n",
    "# X will be a 3D tensor - num_of_sentences * maxlen * total_chars\n",
    "# y will be 2D tensor - sentences * total_chars\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((num_of_sentences, maxlen, len(total_chars)), dtype=np.bool)\n",
    "y = np.zeros((num_of_sentences, len(total_chars)), dtype=np.bool)\n",
    "\n",
    "# populate the tensors\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# lstm takes a single slice of 3D tensor along num_of_sentences axiss\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(total_chars)))) \n",
    "\n",
    "# add a dense layer - takes 128 input and spits output of num_of_chars \n",
    "model.add(Dense(len(total_chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preds is scores over output space (characters)\n",
    "# Its nothing but - confidence the RNN currently assigns to each character coming next in the sequence\n",
    "\n",
    "# we convert scores into probability distribution and pick the best bet. \n",
    "\n",
    "# Temperature. We can also play with the temperature of the Softmax during sampling. Decreasing the temperature \n",
    "# from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. \n",
    "# Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, \n",
    "# etc). In particular, setting temperature very near zero will give the most likely thing\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds) # convert scores to prob via softmax\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas) # return the one with max probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y,batch_size=128,epochs=1)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1) # pick an index at random\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        \n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen] # pick sentence at randomly gerenated index\n",
    "        generated += sentence\n",
    "        \n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        sys.stdout.write(\"\\n\")\n",
    "        \n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(total_chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1. # put the sentence in 1-hot format\n",
    "                \n",
    "            preds = model.predict(x, verbose=0)[0] # make the model spit out predictions\n",
    "            \n",
    "            next_index = sample(preds, diversity) # choose a character index\n",
    "            next_char = indices_char[next_index]  # get the corresponding chracater\n",
    "            \n",
    "            generated += next_char                # append this character to the sentence\n",
    "            sentence = sentence[1:] + next_char   # now shift the the sentence by one character\n",
    "            \n",
    "            sys.stdout.write(next_char)           # write the character to buffer\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
