{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import mpld3\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import math\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from load_imdb_data import load_imdb_data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "np.random.seed(0)\n",
    "from readWikiData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentences, word2idx, idx2word, original_sentence = get_wikipedia_data(n_files=1, n_vocab=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1247, 8, 7, 236, 461, 11, 6706, 10000, 2630, 153, 15, 2879, 1279],\n",
       " 'Anarchism is a political philosophy that advocates self-governed societies based on voluntary institutions',\n",
       " [52,\n",
       "  16,\n",
       "  92,\n",
       "  334,\n",
       "  9,\n",
       "  10000,\n",
       "  2630,\n",
       "  118,\n",
       "  110,\n",
       "  1188,\n",
       "  28,\n",
       "  618,\n",
       "  93,\n",
       "  43,\n",
       "  1306,\n",
       "  9,\n",
       "  1279,\n",
       "  153,\n",
       "  15,\n",
       "  10000,\n",
       "  381,\n",
       "  4530],\n",
       " 'These are often described as stateless societies, although several authors have defined them more specifically as institutions based on non-hierarchical free associations')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0], original_sentence[0], sentences[1], original_sentence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('anarchism', 'is', 'a', 'political')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[1247], idx2word[8], idx2word[7], idx2word[236]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Implement Encoder Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(idx2word)\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, shape=[1])\n",
    "h_t_1 = tf.zeros(shape=(1, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# r_t\n",
    "W_r = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -1.0, 1.0), name=\"W_r\")\n",
    "U_r = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"U_r\")\n",
    "\n",
    "# z_t \n",
    "W_z = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -1.0, 1.0), name=\"W_z\")\n",
    "U_z = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"U_z\")\n",
    "\n",
    "# h_t`\n",
    "W_x = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -1.0, 1.0), name=\"W_x\")\n",
    "U = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"U_z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r_t = tf.sigmoid(tf.nn.embedding_lookup(W_r, x_t) + tf.matmul(h_t_1, U_r))\n",
    "z_t = tf.sigmoid(tf.nn.embedding_lookup(W_z, x_t) + tf.matmul(h_t_1, U_z))\n",
    "h_tt = tf.tanh(tf.nn.embedding_lookup(W_x, x_t) + tf.matmul(r_t * h_t_1, U))\n",
    "h_t = (1 - z_t)*h_t_1 + z_t*h_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.08950575, -0.34388927, -0.09386601, -0.07920617, -0.34724224,\n",
      "         0.004627  , -0.25099581, -0.18330878,  0.32205814,  0.11381489,\n",
      "         0.10609717, -0.34478155, -0.25555316, -0.40183201, -0.32660121,\n",
      "         0.29049969,  0.34218106, -0.16096675,  0.27709273, -0.34433508,\n",
      "        -0.0330869 ,  0.26030418, -0.17714077, -0.27745989,  0.05411258,\n",
      "        -0.04181414, -0.04167271,  0.3831557 ,  0.34315825, -0.16535401,\n",
      "        -0.3470872 , -0.31899625,  0.04079741, -0.07716639, -0.12351626,\n",
      "         0.27795142,  0.17825703,  0.37167796, -0.09916078, -0.4954519 ,\n",
      "         0.10074893, -0.24270521,  0.47293916,  0.24984206, -0.13103037,\n",
      "        -0.19470941,  0.47656071,  0.21887757, -0.29029882,  0.17899357,\n",
      "        -0.21578616,  0.36319333,  0.3535828 , -0.30358949, -0.21026765,\n",
      "        -0.29192999, -0.05463111,  0.20519921,  0.06344624,  0.21165419,\n",
      "         0.2434991 ,  0.00180203, -0.1641418 ,  0.31749913, -0.26395839,\n",
      "        -0.18859619,  0.20362677,  0.04450817, -0.26033702, -0.18684798,\n",
      "        -0.08753487,  0.21781774,  0.2549153 , -0.0656362 ,  0.33826447,\n",
      "        -0.1017635 , -0.04581697,  0.21585849,  0.25627106,  0.13587512,\n",
      "        -0.02279021,  0.43439841, -0.26987353,  0.02349394,  0.14424476,\n",
      "        -0.01262208, -0.15638383,  0.27628934,  0.29037204,  0.12758225,\n",
      "        -0.04975413, -0.11785568,  0.15182345, -0.05278729, -0.2596572 ,\n",
      "        -0.10314586,  0.05843519,  0.07265442, -0.31399304, -0.04680676]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for item in sentences[0]:\n",
    "        output = sess.run([h_t], feed_dict={x_t:[item]})\n",
    "        h_t_1 = output[-1][-1] \n",
    "    print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Implement Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_t_1 = tf.placeholder(tf.int32, shape=[1])\n",
    "h_td_1 = tf.zeros(shape=(1, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_d_r = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -1.0, 1.0), name=\"W_d_r\")\n",
    "U_d_r = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"U_d_r\")\n",
    "C_r = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"C_r\")\n",
    "\n",
    "W_d_z = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -1.0, 1.0), name=\"W_d_z\")\n",
    "U_d_z = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"U_d_z\")\n",
    "C_z = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"C_z\")\n",
    "\n",
    "W_d = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -1.0, 1.0), name=\"W_d\")\n",
    "U_d = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"U_d\")\n",
    "C = tf.Variable(tf.random_uniform([hidden_size, hidden_size], -1.0, 1.0), name=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r_t_d = tf.sigmoid(tf.nn.embedding_lookup(W_d_r, x_t_1) + tf.matmul(h_td_1, U_d_r) + tf.matmul(h_t, C_r))\n",
    "z_t_d = tf.sigmoid(tf.nn.embedding_lookup(W_d_z, x_t_1) + tf.matmul(h_td_1, U_d_z) + tf.matmul(h_t, C_z))\n",
    "h_tt_d = tf.tanh(tf.nn.embedding_lookup(W_d, x_t_1) + tf.matmul(r_t_d * h_td_1, U_d) + tf.matmul(h_t, C))\n",
    "h_t_d = (1 - z_t_d)*h_td_1 + z_t_d*h_tt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "V = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -1.0, 1.0), name=\"V\")\n",
    "v_w = tf.nn.embedding_lookup(V, x_t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.log(tf.exp(tf.matmul(h_t_d, tf.transpose(v_w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at epoch :  0  =  165.031461875\n",
      "Error at epoch :  10  =  165.031461875\n",
      "Error at epoch :  20  =  165.031461875\n",
      "Error at epoch :  30  =  165.031461875\n",
      "Error at epoch :  40  =  165.031461875\n",
      "Error at epoch :  50  =  165.031461875\n",
      "Error at epoch :  60  =  165.031461875\n",
      "Error at epoch :  70  =  165.031461875\n",
      "Error at epoch :  80  =  165.031461875\n",
      "Error at epoch :  90  =  165.031461875\n",
      "Error at epoch :  100  =  165.031461875\n",
      "Error at epoch :  110  =  165.031461875\n",
      "Error at epoch :  120  =  165.031461875\n",
      "Error at epoch :  130  =  165.031461875\n",
      "Error at epoch :  140  =  165.031461875\n",
      "Error at epoch :  150  =  165.031461875\n",
      "Error at epoch :  160  =  165.031461875\n",
      "Error at epoch :  170  =  165.031461875\n",
      "Error at epoch :  180  =  165.031461875\n",
      "Error at epoch :  190  =  165.031461875\n",
      "Error at epoch :  200  =  165.031461875\n",
      "Error at epoch :  210  =  165.031461875\n",
      "Error at epoch :  220  =  165.031461875\n",
      "Error at epoch :  230  =  165.031461875\n",
      "Error at epoch :  240  =  165.031461875\n",
      "Error at epoch :  250  =  165.031461875\n",
      "Error at epoch :  260  =  165.031461875\n",
      "Error at epoch :  270  =  165.031461875\n",
      "Error at epoch :  280  =  165.031461875\n",
      "Error at epoch :  290  =  165.031461875\n",
      "Error at epoch :  300  =  165.031461875\n",
      "Error at epoch :  310  =  165.031461875\n",
      "Error at epoch :  320  =  165.031461875\n",
      "Error at epoch :  330  =  165.031461875\n",
      "Error at epoch :  340  =  165.031461875\n",
      "Error at epoch :  350  =  165.031461875\n",
      "Error at epoch :  360  =  165.031461875\n",
      "Error at epoch :  370  =  165.031461875\n",
      "Error at epoch :  380  =  165.031461875\n",
      "Error at epoch :  390  =  165.031461875\n",
      "Error at epoch :  400  =  165.031461875\n",
      "Error at epoch :  410  =  165.031461875\n",
      "Error at epoch :  420  =  165.031461875\n",
      "Error at epoch :  430  =  165.031461875\n",
      "Error at epoch :  440  =  165.031461875\n",
      "Error at epoch :  450  =  165.031461875\n",
      "Error at epoch :  460  =  165.031461875\n",
      "Error at epoch :  470  =  165.031461875\n",
      "Error at epoch :  480  =  165.031461875\n",
      "Error at epoch :  490  =  165.031461875\n",
      "Error at epoch :  500  =  165.031461875\n",
      "Error at epoch :  510  =  165.031461875\n",
      "Error at epoch :  520  =  165.031461875\n",
      "Error at epoch :  530  =  165.031461875\n",
      "Error at epoch :  540  =  165.031461875\n",
      "Error at epoch :  550  =  165.031461875\n",
      "Error at epoch :  560  =  165.031461875\n",
      "Error at epoch :  570  =  165.031461875\n",
      "Error at epoch :  580  =  165.031461875\n",
      "Error at epoch :  590  =  165.031461875\n",
      "Error at epoch :  600  =  165.031461875\n",
      "Error at epoch :  610  =  165.031461875\n",
      "Error at epoch :  620  =  165.031461875\n",
      "Error at epoch :  630  =  165.031461875\n",
      "Error at epoch :  640  =  165.031461875\n",
      "Error at epoch :  650  =  165.031461875\n",
      "Error at epoch :  660  =  165.031461875\n",
      "Error at epoch :  670  =  165.031461875\n",
      "Error at epoch :  680  =  165.031461875\n",
      "Error at epoch :  690  =  165.031461875\n",
      "Error at epoch :  700  =  165.031461875\n",
      "Error at epoch :  710  =  165.031461875\n",
      "Error at epoch :  720  =  165.031461875\n",
      "Error at epoch :  730  =  165.031461875\n",
      "Error at epoch :  740  =  165.031461875\n",
      "Error at epoch :  750  =  165.031461875\n",
      "Error at epoch :  760  =  165.031461875\n",
      "Error at epoch :  770  =  165.031461875\n",
      "Error at epoch :  780  =  165.031461875\n",
      "Error at epoch :  790  =  165.031461875\n",
      "Error at epoch :  800  =  165.031461875\n",
      "Error at epoch :  810  =  165.031461875\n",
      "Error at epoch :  820  =  165.031461875\n",
      "Error at epoch :  830  =  165.031461875\n",
      "Error at epoch :  840  =  165.031461875\n",
      "Error at epoch :  850  =  165.031461875\n",
      "Error at epoch :  860  =  165.031461875\n",
      "Error at epoch :  870  =  165.031461875\n",
      "Error at epoch :  880  =  165.031461875\n",
      "Error at epoch :  890  =  165.031461875\n",
      "Error at epoch :  900  =  165.031461875\n",
      "Error at epoch :  910  =  165.031461875\n",
      "Error at epoch :  920  =  165.031461875\n",
      "Error at epoch :  930  =  165.031461875\n",
      "Error at epoch :  940  =  165.031461875\n",
      "Error at epoch :  950  =  165.031461875\n",
      "Error at epoch :  960  =  165.031461875\n",
      "Error at epoch :  970  =  165.031461875\n",
      "Error at epoch :  980  =  165.031461875\n",
      "Error at epoch :  990  =  165.031461875\n",
      "Error at epoch :  1000  =  165.031461875\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in xrange(1001):\n",
    "        epoch_error = 0.0 \n",
    "    \n",
    "        for item1, item2 in zip(sentences[:100][:-1], sentences[:100][1:]):\n",
    "            # Encoding step \n",
    "            for item_x in item2:\n",
    "                output_encoder = sess.run([h_t], feed_dict={x_t:[item_x]})\n",
    "                h_t_1 = output_encoder[-1][-1] \n",
    "\n",
    "            h_t_1 = h_t_1.reshape(1, 100)\n",
    "\n",
    "            # Decoding step \n",
    "            for item_y in item1:\n",
    "                output_decoder, word_embeddings = sess.run([h_t_d, v_w], feed_dict={x_t_1:[item_y], \\\n",
    "                                                                                    h_t: h_t_1})\n",
    "            \n",
    "                h_t_1 = output_decoder\n",
    "                \n",
    "                l = sess.run(loss, feed_dict={h_t_d: output_decoder, v_w: word_embeddings})\n",
    "                #if step % 10 == 0:\n",
    "                #    print \"Current loss : %s \" %(l)\n",
    "                epoch_error += l\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print \"Error at epoch : \", step, \" = \", epoch_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_kernel",
   "language": "python",
   "name": "deep_learning_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
